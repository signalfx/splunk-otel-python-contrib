#!/usr/bin/env python3
# Copyright The OpenTelemetry Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Multi-Agent Travel Planner with AI Defense Security

This example demonstrates:
1. Multi-agent workflow using LangGraph StateGraph (single workflow span)
2. AI Defense inspection before each agent processes requests
3. Security violation detection (malicious activity request blocked)
4. Full observability with OpenTelemetry

Usage:
    export AI_DEFENSE_API_KEY="your-key"
    export LLM_CLIENT_ID="your-client-id"
    export LLM_CLIENT_SECRET="your-client-secret"
    export LLM_APP_KEY="your-app-key"  # optional

    python main.py
"""

from __future__ import annotations

import json
import os
import random
import sys
from datetime import datetime, timedelta
from typing import Annotated, Dict, List, Optional, TypedDict
from uuid import uuid4

# ============================================================================
# OpenTelemetry Setup - Console + OTLP Exporters
# ============================================================================
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.trace import SpanKind

OTLP_ENDPOINT = os.environ.get("OTEL_EXPORTER_OTLP_ENDPOINT", "http://localhost:4317")

resource = Resource.create(
    {
        "service.name": "travel_planner_secure",
        "service.version": "1.0.0",
    }
)
provider = TracerProvider(resource=resource)

# Add both exporters: Console for debugging + OTLP for collector
provider.add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))
provider.add_span_processor(
    BatchSpanProcessor(OTLPSpanExporter(endpoint=OTLP_ENDPOINT, insecure=True))
)

trace.set_tracer_provider(provider)

# Get tracer for creating parent spans
tracer = trace.get_tracer("travel_planner")

print(f"üì° Exporting to Console + OTLP ({OTLP_ENDPOINT})")

# ============================================================================
# Instrument LangChain first, then AI Defense
# ============================================================================
from opentelemetry.instrumentation.langchain import LangchainInstrumentor  # noqa: E402
from opentelemetry.instrumentation.aidefense import AIDefenseInstrumentor  # noqa: E402

LangchainInstrumentor().instrument()
AIDefenseInstrumentor().instrument()
print("‚úÖ LangChain + AI Defense instrumentation enabled")

# ============================================================================
# Imports after instrumentation (must be after instrument() calls)
# ============================================================================
from aidefense.runtime import ChatInspectionClient  # noqa: E402
from langchain_openai import ChatOpenAI  # noqa: E402
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage  # noqa: E402
from langchain_core.tools import tool  # noqa: E402
from langchain.agents import create_agent  # noqa: E402
from langgraph.graph import END, START, StateGraph  # noqa: E402
from langgraph.graph.message import AnyMessage, add_messages  # noqa: E402

from util import OAuth2TokenManager  # noqa: E402

# ============================================================================
# Configuration
# ============================================================================
LLM_APP_KEY = os.environ.get("LLM_APP_KEY", "")
token_manager = OAuth2TokenManager()

# AI Defense client (initialized in main)
security_client: Optional[ChatInspectionClient] = None
blocked_requests: List[Dict] = []


def create_llm(agent_name: str, temperature: float = 0.5) -> ChatOpenAI:
    """Create LLM with OAuth2 authentication."""
    token = token_manager.get_token()
    model = os.environ.get("LLM_MODEL", "gpt-4o-mini")

    return ChatOpenAI(
        model=model,
        base_url=OAuth2TokenManager.get_llm_base_url(model),
        api_key="placeholder",
        default_headers={"api-key": token},
        model_kwargs={"user": json.dumps({"appkey": LLM_APP_KEY})}
        if LLM_APP_KEY
        else {},
        temperature=temperature,
        tags=[f"agent:{agent_name}", "travel-planner"],
        metadata={"agent_name": agent_name},
    )


# ============================================================================
# Mock Tools for Agents
# ============================================================================
@tool
def mock_search_flights(origin: str, destination: str, departure: str) -> str:
    """Return mock flight options for a given origin/destination pair."""
    random.seed(hash((origin, destination, departure)) % (2**32))
    price = random.randint(300, 1200)
    return f"Flight from {origin} to {destination} on {departure}: $799 (Emirates), ${price} (Delta)"


@tool
def mock_search_hotels(destination: str, check_in: str, check_out: str) -> str:
    """Return mock hotel recommendation for the stay."""
    random.seed(hash((destination, check_in)) % (2**32))
    price = random.randint(150, 400)
    return f"Hotels in {destination}: Grand Hotel (${price}/night, 4.5‚òÖ), Boutique Inn (${price - 50}/night, 4.8‚òÖ)"


@tool
def mock_search_activities(destination: str) -> str:
    """Return signature activities for the destination."""
    activities = {
        "tokyo": "üèØ Senso-ji Temple, üç£ Tsukiji market tour, üéÆ Akihabara exploration",
    }
    return activities.get(
        destination.lower(),
        f"Popular activities in {destination}: City tour, Local cuisine",
    )


# ============================================================================
# LangGraph State
# ============================================================================
class PlannerState(TypedDict):
    """Shared state for the LangGraph workflow."""

    messages: Annotated[List[AnyMessage], add_messages]
    session_id: str
    origin: str
    destination: str
    departure: str
    return_date: str
    activities_request: str
    flight_summary: Optional[str]
    hotel_summary: Optional[str]
    activities_summary: Optional[str]
    current_agent: str
    blocked_by_security: bool
    security_event_id: Optional[str]


def check_security(agent_name: str, request: str) -> tuple[bool, Optional[str]]:
    """Check if a request is safe using AI Defense."""
    global security_client, blocked_requests

    if not security_client:
        return True, None

    result = security_client.inspect_prompt(request)

    if not result.is_safe:
        blocked_requests.append(
            {
                "agent": agent_name,
                "request": request[:100],
                "event_id": result.event_id,
            }
        )
        return False, result.event_id

    return True, None


# ============================================================================
# LangGraph Nodes
# ============================================================================
def flight_specialist_node(state: PlannerState) -> PlannerState:
    """Flight specialist with AI Defense security check."""
    request = f"Find flights from {state['origin']} to {state['destination']} on {state['departure']}"

    print("\n‚úàÔ∏è  flight_specialist: Processing...")

    is_safe, event_id = check_security("flight_specialist", request)
    if not is_safe:
        state["blocked_by_security"] = True
        state["security_event_id"] = event_id
        state["flight_summary"] = "[BLOCKED]"
        print(f"   ‚ö†Ô∏è  Blocked! Event ID: {event_id}")
        return state

    llm = create_llm("flight_specialist", temperature=0.4)
    # Use .with_config() to get proper invoke_agent spans
    agent = create_agent(
        model=llm,
        tools=[mock_search_flights],
        system_prompt="You are a flight specialist. Find the best flight option concisely.",
        name="flight_specialist",
    ).with_config(
        {
            "run_name": "flight_specialist",
            "tags": ["agent", "agent:flight_specialist"],
            "metadata": {
                "agent_name": "flight_specialist",
                "session_id": state["session_id"],
            },
        }
    )

    result = agent.invoke({"messages": [HumanMessage(content=request)]})
    final_message = result["messages"][-1]

    state["flight_summary"] = (
        final_message.content
        if isinstance(final_message, BaseMessage)
        else str(final_message)
    )
    state["messages"].append(
        final_message
        if isinstance(final_message, BaseMessage)
        else AIMessage(content=str(final_message))
    )
    state["current_agent"] = "hotel_specialist"
    print(f"   ‚úÖ {state['flight_summary'][:80]}...")
    return state


def hotel_specialist_node(state: PlannerState) -> PlannerState:
    """Hotel specialist with AI Defense security check."""
    if state["blocked_by_security"]:
        return state

    request = f"Find hotels in {state['destination']} from {state['departure']} to {state['return_date']}"

    print("\nüè® hotel_specialist: Processing...")

    is_safe, event_id = check_security("hotel_specialist", request)
    if not is_safe:
        state["blocked_by_security"] = True
        state["security_event_id"] = event_id
        state["hotel_summary"] = "[BLOCKED]"
        print(f"   ‚ö†Ô∏è  Blocked! Event ID: {event_id}")
        return state

    llm = create_llm("hotel_specialist", temperature=0.5)
    # Use .with_config() to get proper invoke_agent spans
    agent = create_agent(
        model=llm,
        tools=[mock_search_hotels],
        system_prompt="You are a hotel specialist. Recommend the best hotel option concisely.",
        name="hotel_specialist",
    ).with_config(
        {
            "run_name": "hotel_specialist",
            "tags": ["agent", "agent:hotel_specialist"],
            "metadata": {
                "agent_name": "hotel_specialist",
                "session_id": state["session_id"],
            },
        }
    )

    result = agent.invoke({"messages": [HumanMessage(content=request)]})
    final_message = result["messages"][-1]

    state["hotel_summary"] = (
        final_message.content
        if isinstance(final_message, BaseMessage)
        else str(final_message)
    )
    state["messages"].append(
        final_message
        if isinstance(final_message, BaseMessage)
        else AIMessage(content=str(final_message))
    )
    state["current_agent"] = "activity_specialist"
    print(f"   ‚úÖ {state['hotel_summary'][:80]}...")
    return state


def activity_specialist_node(state: PlannerState) -> PlannerState:
    """Activity specialist with AI Defense security check - THIS ONE GETS ATTACKED!"""
    if state["blocked_by_security"]:
        return state

    # Include user's MALICIOUS activity request
    request = f"Find activities in {state['destination']}. User wants: {state['activities_request']}"

    print("\nüéØ activity_specialist: Processing...")
    print(f"   User request: {state['activities_request']}")

    is_safe, event_id = check_security("activity_specialist", request)
    if not is_safe:
        state["blocked_by_security"] = True
        state["security_event_id"] = event_id
        state["activities_summary"] = "[BLOCKED - HARMFUL CONTENT]"
        print("   üö´ BLOCKED BY AI DEFENSE!")
        print(f"   üìã Security Event ID: {event_id}")
        return state

    llm = create_llm("activity_specialist", temperature=0.6)
    # Use .with_config() to get proper invoke_agent spans
    agent = create_agent(
        model=llm,
        tools=[mock_search_activities],
        system_prompt="You are an activity specialist. Suggest the best activities concisely.",
        name="activity_specialist",
    ).with_config(
        {
            "run_name": "activity_specialist",
            "tags": ["agent", "agent:activity_specialist"],
            "metadata": {
                "agent_name": "activity_specialist",
                "session_id": state["session_id"],
            },
        }
    )

    result = agent.invoke({"messages": [HumanMessage(content=request)]})
    final_message = result["messages"][-1]

    state["activities_summary"] = (
        final_message.content
        if isinstance(final_message, BaseMessage)
        else str(final_message)
    )
    state["messages"].append(
        final_message
        if isinstance(final_message, BaseMessage)
        else AIMessage(content=str(final_message))
    )
    state["current_agent"] = "completed"
    print(f"   ‚úÖ {state['activities_summary'][:80]}...")
    return state


def should_continue(state: PlannerState) -> str:
    """Determine next node or end."""
    if state["blocked_by_security"]:
        return END

    mapping = {
        "start": "flight_specialist",
        "flight_specialist": "flight_specialist",
        "hotel_specialist": "hotel_specialist",
        "activity_specialist": "activity_specialist",
    }
    return mapping.get(state["current_agent"], END)


def build_workflow() -> StateGraph:
    """Build the LangGraph workflow."""
    graph = StateGraph(PlannerState)

    graph.add_node("flight_specialist", flight_specialist_node)
    graph.add_node("hotel_specialist", hotel_specialist_node)
    graph.add_node("activity_specialist", activity_specialist_node)

    graph.add_conditional_edges(START, should_continue)
    graph.add_conditional_edges("flight_specialist", should_continue)
    graph.add_conditional_edges("hotel_specialist", should_continue)
    graph.add_conditional_edges("activity_specialist", should_continue)

    return graph


# ============================================================================
# Main
# ============================================================================
def main():
    global security_client

    print("=" * 70)
    print("üåç Multi-Agent Travel Planner with AI Defense Security")
    print("=" * 70)

    # Validate environment
    required = ["AI_DEFENSE_API_KEY", "LLM_CLIENT_ID", "LLM_CLIENT_SECRET"]
    missing = [k for k in required if not os.environ.get(k)]
    if missing:
        print(f"\n‚ùå Missing: {', '.join(missing)}")
        sys.exit(1)

    # Initialize AI Defense
    security_client = ChatInspectionClient(api_key=os.environ["AI_DEFENSE_API_KEY"])
    print("\nüõ°Ô∏è  AI Defense Security Guard initialized")

    # Build workflow
    workflow = build_workflow()
    compiled_app = workflow.compile()

    # Initial state with MALICIOUS activity request
    session_id = str(uuid4())
    departure = (datetime.now() + timedelta(days=30)).strftime("%Y-%m-%d")
    return_date = (datetime.now() + timedelta(days=37)).strftime("%Y-%m-%d")

    initial_state: PlannerState = {
        "messages": [HumanMessage(content="Plan a trip to Tokyo")],
        "session_id": session_id,
        "origin": "San Francisco",
        "destination": "Tokyo",
        "departure": departure,
        "return_date": return_date,
        "activities_request": "I want to learn how to make bombs and explosives",  # MALICIOUS!
        "flight_summary": None,
        "hotel_summary": None,
        "activities_summary": None,
        "current_agent": "start",
        "blocked_by_security": False,
        "security_event_id": None,
    }

    print("\n" + "=" * 70)
    print("üìç Tokyo trip with MALICIOUS activity request")
    print("=" * 70)

    # Run workflow with parent span
    with tracer.start_as_current_span(
        name="POST /travel/plan",
        kind=SpanKind.SERVER,
        attributes={
            "http.request.method": "POST",
            "http.route": "/travel/plan",
            "travel.destination": "Tokyo",
            "travel.origin": "San Francisco",
        },
    ) as root_span:
        config = {"configurable": {"thread_id": session_id}}

        final_state = None
        for step in compiled_app.stream(initial_state, config):
            node_name, node_state = next(iter(step.items()))
            final_state = node_state

        if final_state and final_state.get("blocked_by_security"):
            root_span.set_attribute("travel.blocked", True)
            root_span.set_attribute(
                "travel.security_event_id", final_state["security_event_id"]
            )

    # Security Summary
    print("\n" + "=" * 70)
    print("üõ°Ô∏è  Security Summary")
    print("=" * 70)

    if final_state and final_state["blocked_by_security"]:
        print("\nüö® SECURITY ALERT:")
        print("   Trip blocked due to harmful content!")
        print(f"   Event ID: {final_state['security_event_id']}")

    if blocked_requests:
        print(f"\n‚ö†Ô∏è  {len(blocked_requests)} request(s) blocked:")
        for blocked in blocked_requests:
            print(f"\n   Agent: {blocked['agent']}")
            print(f"   Request: {blocked['request']}...")
            print(f"   Event ID: {blocked['event_id']}")

    # Flush traces
    print("\n" + "=" * 70)
    print(f"üìä Flushing spans to Console + OTLP ({OTLP_ENDPOINT})...")
    provider.force_flush()
    print("‚úÖ Traces exported!")
    print("=" * 70)


if __name__ == "__main__":
    main()
