# =============================================================================
# LLM Configuration - Choose ONE option:
# =============================================================================

# Option 1: OpenAI API (direct)
# OPENAI_API_KEY=your-openai-api-key-here

# Option 2: OAuth2 LLM Provider (via LiteLLM)
LLM_CLIENT_ID=your-client-id
LLM_CLIENT_SECRET=your-client-secret
LLM_TOKEN_URL=https://your-identity-provider/oauth2/token
LLM_BASE_URL=https://your-llm-gateway/openai/deployments
LLM_APP_KEY=your-app-key

# =============================================================================
# OpenTelemetry Configuration
# =============================================================================

# Service name for telemetry
OTEL_SERVICE_NAME=crewai-zero-code

# OTLP Exporter - Local collector
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OTEL_EXPORTER_OTLP_PROTOCOL=grpc

# OTLP Exporter - Splunk Observability Cloud (HTTP required for custom paths)
OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://ingest.us1.signalfx.com/v2/trace/otlp
OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=https://ingest.us1.signalfx.com/v2/datapoint/otlp
OTEL_EXPORTER_OTLP_HEADERS=X-SF-Token=YOUR_SPLUNK_ACCESS_TOKEN

# Enable metrics (required for gen_ai.agent.duration, gen_ai.workflow.duration)
OTEL_INSTRUMENTATION_GENAI_EMITTERS=span_metric

# Capture message content in spans (optional, may contain sensitive data)
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true

# =============================================================================
# CrewAI Configuration
# =============================================================================

# Disable CrewAI built-in telemetry (recommended)
CREWAI_DISABLE_TELEMETRY=true

# OpenAI Model (used by LiteLLM)
OPENAI_MODEL_NAME=gpt-4o-mini


