[pytest]
# O11y AI Test Automation Framework - Pytest Configuration

# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Markers for test categorization
markers =
    p0: Priority 0 tests (critical for GA)
    p1: Priority 1 tests (important but not blocking)
    p2: Priority 2 tests (nice to have)
    e2e: End-to-end tests
    api: API tests
    ui: UI tests
    integration: Integration tests
    smoke: Smoke tests
    regression: Regression tests
    slow: Tests that take longer than 30 seconds
    flaky: Known flaky tests (will be retried)
    genai: GenAI semantic conventions validation tests
    aoan: Agent Observability & Analytics Navigator tests
    evaluation: Evaluation metrics validation tests
    ai_defense: AI Defense security event tests
    streaming: Streaming response tests
    token_usage: Token usage validation tests
    cost: Cost tracking validation tests

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = reports/test_execution.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(filename)s:%(lineno)d] %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Console output
console_output_style = progress
verbosity = 2

# Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Timeout (in seconds)
timeout = 300
timeout_method = thread

# Parallel execution
addopts = 
    --strict-markers
    --tb=short
    --html=reports/html/report.html
    --self-contained-html
    --json-report
    --json-report-file=reports/json/report.json
    --alluredir=reports/allure-results
    -ra

# Playwright specific
playwright_browser = chromium
playwright_headless = true
playwright_slow_mo = 0

# Retry failed tests
reruns = 2
reruns_delay = 5
